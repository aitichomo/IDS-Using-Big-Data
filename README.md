# Intrusion Detection System Using Big Data

This repository contains the implementation of an Intrusion Detection System (IDS) leveraging Big Data technologies and machine learning techniques to detect network intrusions effectively.

## Overview

Our IDS solution utilizes deep learning models to analyze network traffic and identify potential threats in real-time. By harnessing the power of Big Data, the system can process and analyze large volumes of network data efficiently using KDD Cup data set.

<img width="824" alt="architecture (1)" src="https://github.com/user-attachments/assets/2fe63f9c-0918-4cc1-b8a9-65b40b84a0e4">

## Key Features

- **Real-time Detection**: Capable of identifying network intrusions in real-time.
- **Big Data Integration**: Utilizes Big Data technologies for scalable and efficient data processing.
- **Machine Learning Models**: Implements various deep learning models for accurate intrusion detection.
- **Data Preprocessing**: Includes comprehensive data preprocessing steps to handle raw network data.

### Prerequisites

- Python 3.x
- Apache Kafka
- TensorFlow
- Keras
- NumPy
- Pandas
- Scikit-learn
- Matplotlib
- Spark

# Commands to Execute Real-Time System Operations
## Start zookeeper. 
Kafka server needs this one. It will run on localhost, port 2181
```
kafka_2.13-3.7.0/bin/zookeeper-server-start.sh kafka_2.13-3.7.0/config/zookeeper.properties
```

## Start Kafka server. 

It will run on localhost, port 9092. When we publish messages to this server through producers, messages will be stored on /tmp/kafka-logs/
```
kafka_2.13-3.7.0/bin/kafka-server-start.sh kafka_2.13-3.7.0/config/server.properties
```

<!-- Start tcpdump. This will write a pcap file every 30 seconds to folder data/raw_pcap. Names of pcap files are the timestamps of the moment writing files.
```
tcpdump -i enp0s3 -w data/raw_pcap/%s.pcap -G 30
```
 -->
<!-- Convert data from pcap to readable files. Then producer sends data to Kafka.
```
python3 producer.py
```
 -->
 
## Configuration for Snort
Snort needs a config file (**snort.config**) and a folder to store log. Normally, they are stored in **/etc/snort/snort.config** and **/var/logs/snort**.

In this project, we store them in folder **snort** and use the *full paths* to point where they are.
### snort.config
In this file, we point to the file **rules/icmp.rules**
```
include rules/icmp.rules
```
### Rules
We write some rules to capture packets in config file. In this example, sort will alert all ping packets.
```
alert icmp any any -> any any (msg:"ICMP Packet"; sid:477; rev:3;)
```
### Start snort to capture packes
```
sudo snort -c snort/snort.config -A full -i enp0s3 -b -l snort/logs
```

## ping to somewhere to test snort
```
ping google.com
```

## Run producer to send pcap logs to kafka.
```
python3 producer_pcap.py
```

## Run consumer of spark
This consumer retrieves pcaps from kafka, then transform to readable data thanks to **Zeek**. After that, KDD99 data is generated by spark. TensorFlow models then predict whether data is normal or attacked. The results are sent back to kafka.
```
python3 consumer_spark.py
```

## Run consumer of warning
This consumer retrieves and shows predicted data from kafka
```
python3 consumer_warning.py
```
Notice: all commands should be run from Real-Time-IDS-Test

